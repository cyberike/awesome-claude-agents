import tensorflow as tf\n\ndef quantize_model(model_path, quantized_model_path):\n    """Quantize a saved model for optimization.\n    \n    Args:\n        model_path: Path to the saved model directory.\n        quantized_model_path: Path to save the quantized model.\n    """\n    # Load the saved model\n    model = tf.keras.models.load_model(model_path)\n    \n    # Convert the model to TensorFlow Lite format with quantization\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n    quantized_tflite_model = converter.convert()\n    \n    # Save the quantized model\n    with open(quantized_model_path, 'wb') as f:\n        f.write(quantized_tflite_model)\n    print(f'Quantized model saved at: {quantized_model_path}')\n\ndef evaluate_quantized_model(quantized_model_path, test_data):\n    """Evaluate the quantized model on test data.\n    \n    Args:\n        quantized_model_path: Path to the quantized model file.\n        test_data: Test data to evaluate the model.\n    """\n    # Load the quantized model\n    interpreter = tf.lite.Interpreter(model_path=quantized_model_path)\n    interpreter.allocate_tensors()\n    \n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    \n    # Evaluate on test data\n    total_samples = len(test_data)\n    accuracy = 0\n    \n    for data, label in test_data:\n        interpreter.set_tensor(input_details[0]['index'], [data])\n        interpreter.invoke()\n        output = interpreter.get_tensor(output_details[0]['index'])\n        \n        # Check if prediction matches expected\n        if output.argmax() == label:\n            accuracy += 1\n    \n    accuracy /= total_samples\n    print(f'Quantized model accuracy: {accuracy:.4f}')\n\n# Example usage\nsaved_model_path = 'path/to/saved/model'\nquantized_model_file = 'quantized_model.tflite'\nquantize_model(saved_model_path, quantized_model_file)\n\ntest_data = [...] # Load or generate test data\nevaluate_quantized_model(quantized_model_file, test_data)\n