import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = "facebook/opt-125m"\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nquantized_model = torch.quantization.quantize_dynamic(\n    model, {torch.nn.Linear}, dtype=torch.qint8\n)\n\noptimizer = torch.optim.Adam(quantized_model.parameters(), lr=1e-5)\n\nfor epoch in range(3):\n    optimizer.zero_grad()\n    input_ids = tokenizer.encode("Hello, how are you?", return_tensors="pt")\n    loss = quantized_model(input_ids, labels=input_ids)[0]\n    loss.backward()\n    optimizer.step()\n\nprint("Optimized quantized model for edge devices.")\n\nquantized_model.save_pretrained("optimized_quantized_model")\ntokenizer.save_pretrained("optimized_quantized_model")\n