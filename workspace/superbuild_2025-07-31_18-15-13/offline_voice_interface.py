import pyaudio\nimport wave\nimport speech_recognition as sr\nfrom transformers import pipeline\n\nquantized_model_path = "quantized_model"\ngenerator = pipeline("text-generation", model=quantized_model_path)\n\nDEVICE_INDEX = 1\nFORMAT = pyaudio.paInt16\nCHANNELS = 1\nRATE = 44100\nCHUNK = 1024\nDURATION = 5\n\np = pyaudio.PyAudio()\nstream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n                input=True, input_device_index=DEVICE_INDEX,\n                frames_per_buffer=CHUNK)\n\nprint("Recording...")\nframes = []\nfor i in range(0, int(RATE / CHUNK * DURATION)):\n    data = stream.read(CHUNK)\n    frames.append(data)\nprint("Recording finished.")\n\nstream.stop_stream()\nstream.close()\np.terminate()\n\nwf = wave.open("recorded_audio.wav", 'wb')\nwf.setnchannels(CHANNELS)\nwf.setsampwidth(p.get_sample_size(FORMAT))\nwf.setframerate(RATE)\nwf.writeframes(b''.join(frames))\nwf.close()\n\nr = sr.Recognizer()\nwith sr.AudioFile("recorded_audio.wav") as source:\n    audio = r.record(source)\n\ntry:\n    text = r.recognize_google(audio)\n    print(f"Recognized speech: {text}")\n    \n    response = generator(text, max_length=50)[0]["generated_text"]\n    print(f"Generated response: {response}")\n    \nexcept sr.UnknownValueError:\n    print("Could not understand audio")\nexcept sr.RequestError as e:\n    print(f"Could not request results; {e}")\n