import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = "facebook/opt-125m"\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nquantized_model = torch.quantization.quantize_dynamic(\n    model, {torch.nn.Linear}, dtype=torch.qint8\n)\n\nquantized_model = quantized_model.to('cpu')\nquantized_model = torch.jit.script(quantized_model)\nquantized_model = torch.jit.optimize_for_inference(quantized_model)\n\ntorch.jit.save(quantized_model, "quantized_model_edge.pt")\ntokenizer.save_pretrained("quantized_model_edge")\n